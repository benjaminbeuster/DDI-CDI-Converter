{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "067ce98c-9018-4f4a-b96c-a010acbd7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyreadstat as pyr\n",
    "import json\n",
    "import numpy as np\n",
    "from spss_import import read_sav \n",
    "pd.set_option('display.max_rows', 2500)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b3ad9d-5958-473e-a2ae-1ad0e9559984",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Out of bounds nanosecond timestamp: 1582-10-14 00:00:00 present at position 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\dev\\DDICDI_generator\\spss_import.py:24\u001b[0m, in \u001b[0;36mread_sav\u001b[1;34m(filename, encoding, missings)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     df, meta \u001b[38;5;241m=\u001b[39m pyr\u001b[38;5;241m.\u001b[39mread_sav(filename, encoding\u001b[38;5;241m=\u001b[39mencoding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mpyreadstat\\pyreadstat.pyx:384\u001b[0m, in \u001b[0;36mpyreadstat.pyreadstat.read_sav\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyreadstat\\_readstat_parser.pyx:1133\u001b[0m, in \u001b[0;36mpyreadstat._readstat_parser.run_conversion\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyreadstat\\_readstat_parser.pyx:932\u001b[0m, in \u001b[0;36mpyreadstat._readstat_parser.dict_to_pandas_dataframe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1068\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1068\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m     result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:438\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    437\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 438\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2177\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2182\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2186\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:427\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:678\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:674\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:542\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\_libs\\tslibs\\np_datetime.pyx:212\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 1582-10-14 00:00:00 present at position 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m spssfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles/ESS10_ptw_compl_HU.sav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m df, df_meta \u001b[38;5;241m=\u001b[39m \u001b[43mread_sav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspssfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\dev\\DDICDI_generator\\spss_import.py:26\u001b[0m, in \u001b[0;36mread_sav\u001b[1;34m(filename, encoding, missings)\u001b[0m\n\u001b[0;32m     24\u001b[0m         df, meta \u001b[38;5;241m=\u001b[39m pyr\u001b[38;5;241m.\u001b[39mread_sav(filename, encoding\u001b[38;5;241m=\u001b[39mencoding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m         df, meta \u001b[38;5;241m=\u001b[39m pyr\u001b[38;5;241m.\u001b[39mread_sav(filename, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLATIN1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.dta\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mpyreadstat\\pyreadstat.pyx:384\u001b[0m, in \u001b[0;36mpyreadstat.pyreadstat.read_sav\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyreadstat\\_readstat_parser.pyx:1133\u001b[0m, in \u001b[0;36mpyreadstat._readstat_parser.run_conversion\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyreadstat\\_readstat_parser.pyx:932\u001b[0m, in \u001b[0;36mpyreadstat._readstat_parser.dict_to_pandas_dataframe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1068\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1068\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:438\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_datetime_format\n\u001b[0;32m    437\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 438\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    451\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2175\u001b[0m order: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2177\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2182\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2186\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m   2187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   2188\u001b[0m     \u001b[38;5;66;03m# Exception is raised when a part of date is greater than 32 bit signed int\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:427\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:678\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:674\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:542\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\bbe088\\dev\\ddicdi_generator\\venv\\lib\\site-packages\\pandas\\_libs\\tslibs\\np_datetime.pyx:212\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 1582-10-14 00:00:00 present at position 1"
     ]
    }
   ],
   "source": [
    "spssfile = f\"files/ESS10_ptw_compl_HU.sav\"\n",
    "df, df_meta = read_sav(spssfile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1511ff74-4255-4135-aacd-87a92c7c8de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>essround</th>\n",
       "      <th>edition</th>\n",
       "      <th>proddate</th>\n",
       "      <th>idno</th>\n",
       "      <th>cntry</th>\n",
       "      <th>dweight</th>\n",
       "      <th>pspwght</th>\n",
       "      <th>pweight</th>\n",
       "      <th>anweight</th>\n",
       "      <th>prob</th>\n",
       "      <th>stratum</th>\n",
       "      <th>psu</th>\n",
       "      <th>nwspol</th>\n",
       "      <th>netusoft</th>\n",
       "      <th>netustm</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESS9e03_1</td>\n",
       "      <td>9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>17.02.2021</td>\n",
       "      <td>27</td>\n",
       "      <td>AT</td>\n",
       "      <td>0.581174</td>\n",
       "      <td>0.218111</td>\n",
       "      <td>0.302091</td>\n",
       "      <td>0.06589</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>59</td>\n",
       "      <td>1688</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESS9e03_1</td>\n",
       "      <td>9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>17.02.2021</td>\n",
       "      <td>137</td>\n",
       "      <td>AT</td>\n",
       "      <td>1.062772</td>\n",
       "      <td>0.413473</td>\n",
       "      <td>0.302091</td>\n",
       "      <td>0.124907</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>79</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESS9e03_1</td>\n",
       "      <td>9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>17.02.2021</td>\n",
       "      <td>194</td>\n",
       "      <td>AT</td>\n",
       "      <td>1.376509</td>\n",
       "      <td>2.270293</td>\n",
       "      <td>0.302091</td>\n",
       "      <td>0.685836</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>11</td>\n",
       "      <td>938</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESS9e03_1</td>\n",
       "      <td>9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>17.02.2021</td>\n",
       "      <td>208</td>\n",
       "      <td>AT</td>\n",
       "      <td>0.993399</td>\n",
       "      <td>0.386483</td>\n",
       "      <td>0.302091</td>\n",
       "      <td>0.116753</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>74</td>\n",
       "      <td>1998</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESS9e03_1</td>\n",
       "      <td>9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>17.02.2021</td>\n",
       "      <td>220</td>\n",
       "      <td>AT</td>\n",
       "      <td>0.377353</td>\n",
       "      <td>1.032102</td>\n",
       "      <td>0.302091</td>\n",
       "      <td>0.311789</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>99</td>\n",
       "      <td>601</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  essround edition    proddate  idno cntry   dweight   pspwght  \\\n",
       "0  ESS9e03_1         9     3.1  17.02.2021    27    AT  0.581174  0.218111   \n",
       "1  ESS9e03_1         9     3.1  17.02.2021   137    AT  1.062772  0.413473   \n",
       "2  ESS9e03_1         9     3.1  17.02.2021   194    AT  1.376509  2.270293   \n",
       "3  ESS9e03_1         9     3.1  17.02.2021   208    AT  0.993399  0.386483   \n",
       "4  ESS9e03_1         9     3.1  17.02.2021   220    AT  0.377353  1.032102   \n",
       "\n",
       "    pweight  anweight      prob  stratum   psu  nwspol  netusoft netustm  \\\n",
       "0  0.302091   0.06589  0.001176       59  1688      60         5     180   \n",
       "1  0.302091  0.124907  0.000643       79    88      10         5      20   \n",
       "2  0.302091  0.685836  0.000496       11   938      60         4     180   \n",
       "3  0.302091  0.116753  0.000688       74  1998      45         5     120   \n",
       "4  0.302091  0.311789  0.001811       99   601      30         1       a   \n",
       "\n",
       "   ppltrst  pplfair  pplhlp  \n",
       "0        2        2       2  \n",
       "1        7        8       7  \n",
       "2        5        7       7  \n",
       "3        3        9       5  \n",
       "4        5        8       4  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spssfile2 = f\"files/ESS-Data-Wizard-subset-2023-10-23.dta\"\n",
    "df2, df2_meta = read_sav(spssfile2)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aef21f4c-43c0-423e-8eb6-958cef0f2cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>format</th>\n",
       "      <th>measure</th>\n",
       "      <th>label</th>\n",
       "      <th>values</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RID</td>\n",
       "      <td>F8.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>Respondent ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MARST</td>\n",
       "      <td>F8.0</td>\n",
       "      <td>nominal</td>\n",
       "      <td>Marital Status</td>\n",
       "      <td>{1.0: 'Single', 2.0: 'Married', 3.0: 'In a civ...</td>\n",
       "      <td>[{'lo': 7.0, 'hi': 8.0}, {'lo': 9.0, 'hi': 9.0}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PWT</td>\n",
       "      <td>F8.2</td>\n",
       "      <td>scale</td>\n",
       "      <td>Person Weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'lo': -8.0, 'hi': -8.0}, {'lo': -9.0, 'hi': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testvar</td>\n",
       "      <td>A1</td>\n",
       "      <td>nominal</td>\n",
       "      <td>testvar label</td>\n",
       "      <td>{'1': 'substantive', '7': 'missing1', '8': 'mi...</td>\n",
       "      <td>[{'lo': '7', 'hi': '7'}, {'lo': '8', 'hi': '8'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name format  measure           label  \\\n",
       "0      RID   F8.0    scale   Respondent ID   \n",
       "1    MARST   F8.0  nominal  Marital Status   \n",
       "2      PWT   F8.2    scale   Person Weight   \n",
       "3  testvar     A1  nominal   testvar label   \n",
       "\n",
       "                                              values  \\\n",
       "0                                                NaN   \n",
       "1  {1.0: 'Single', 2.0: 'Married', 3.0: 'In a civ...   \n",
       "2                                                NaN   \n",
       "3  {'1': 'substantive', '7': 'missing1', '8': 'mi...   \n",
       "\n",
       "                                             missing  \n",
       "0                                                NaN  \n",
       "1   [{'lo': 7.0, 'hi': 8.0}, {'lo': 9.0, 'hi': 9.0}]  \n",
       "2  [{'lo': -8.0, 'hi': -8.0}, {'lo': -9.0, 'hi': ...  \n",
       "3  [{'lo': '7', 'hi': '7'}, {'lo': '8', 'hi': '8'...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_variable_view(df_meta):\n",
    "    # Extract the attributes from df_meta\n",
    "    label = df_meta.column_names_to_labels\n",
    "    values = df_meta.variable_value_labels\n",
    "    missing = df_meta.missing_ranges\n",
    "    format = df_meta.original_variable_types\n",
    "    measure = df_meta.variable_measure\n",
    "\n",
    "    # Convert dictionaries into individual dataframes\n",
    "    df_label = pd.DataFrame(list(label.items()), columns=['name', 'label'])\n",
    "    df_format = pd.DataFrame(list(format.items()), columns=['name', 'format'])\n",
    "    df_measure = pd.DataFrame(list(measure.items()), columns=['name', 'measure'])\n",
    "\n",
    "    # For values and missing, handle them differently due to dictionaries/lists inside\n",
    "    df_values_list = [{'name': k, 'values': str(v)} for k, v in values.items()]  # Convert values to string\n",
    "    df_values = pd.DataFrame(df_values_list)\n",
    "\n",
    "    df_missing_list = [{'name': k, 'missing': str(v)} for k, v in missing.items()]  # Convert missing values to string\n",
    "    df_missing = pd.DataFrame(df_missing_list)\n",
    "\n",
    "    # Merge dataframes on the 'name' column\n",
    "    variable_view = df_label\n",
    "    if not df_values.empty:\n",
    "        variable_view = variable_view.merge(df_values, on='name', how='outer')\n",
    "    \n",
    "    if not df_missing.empty:\n",
    "        variable_view = variable_view.merge(df_missing, on='name', how='outer')\n",
    "\n",
    "    variable_view = variable_view \\\n",
    "        .merge(df_format, on='name', how='outer') \\\n",
    "        .merge(df_measure, on='name', how='outer')\n",
    "\n",
    "    # Ensure 'values' and 'missing' columns are present\n",
    "    if 'values' not in variable_view.columns:\n",
    "        variable_view['values'] = pd.NA\n",
    "\n",
    "    if 'missing' not in variable_view.columns:\n",
    "        variable_view['missing'] = pd.NA\n",
    "\n",
    "    return variable_view[['name', 'format', 'measure', 'label', 'values', 'missing']]\n",
    "\n",
    "\n",
    "create_variable_view(df_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b94eae7-09cb-4998-a0c2-ce998b7e42e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>values</th>\n",
       "      <th>missing</th>\n",
       "      <th>format</th>\n",
       "      <th>measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>Title of dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%9s</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>essround</td>\n",
       "      <td>ESS round</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%3.0g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edition</td>\n",
       "      <td>Edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%3s</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proddate</td>\n",
       "      <td>Production date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%10s</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>idno</td>\n",
       "      <td>Respondent's identification number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%8.0g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cntry</td>\n",
       "      <td>Country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%2s</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dweight</td>\n",
       "      <td>Design weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%3.2g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pspwght</td>\n",
       "      <td>Post-stratification weight including design we...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%3.2g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pweight</td>\n",
       "      <td>Population size weight (must be combined with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%3.2g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anweight</td>\n",
       "      <td>Analysis weight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%4.2g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>prob</td>\n",
       "      <td>Sampling probability</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%3.2g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stratum</td>\n",
       "      <td>Sampling stratum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%6.0g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>psu</td>\n",
       "      <td>Primary sampling unit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%7.0g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nwspol</td>\n",
       "      <td>News about politics and current affairs, watch...</td>\n",
       "      <td>{'a': 'Refusal', 'b': \"Don't know\", 'c': 'No a...</td>\n",
       "      <td>[{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...</td>\n",
       "      <td>%6.0g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>netusoft</td>\n",
       "      <td>Internet use, how often</td>\n",
       "      <td>{1: 'Never', 2: 'Only occasionally', 3: 'A few...</td>\n",
       "      <td>[{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...</td>\n",
       "      <td>%3.0g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>netustm</td>\n",
       "      <td>Internet use, how much time on typical day, in...</td>\n",
       "      <td>{'a': 'Not applicable', 'b': 'Refusal', 'c': \"...</td>\n",
       "      <td>[{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...</td>\n",
       "      <td>%6.0g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ppltrst</td>\n",
       "      <td>Most people can be trusted or you can't be too...</td>\n",
       "      <td>{0: \"You can't be too careful\", 1: '1', 2: '2'...</td>\n",
       "      <td>[{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...</td>\n",
       "      <td>%4.0g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pplfair</td>\n",
       "      <td>Most people try to take advantage of you, or t...</td>\n",
       "      <td>{0: 'Most people try to take advantage of me',...</td>\n",
       "      <td>[{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...</td>\n",
       "      <td>%4.0g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pplhlp</td>\n",
       "      <td>Most of the time people helpful or mostly look...</td>\n",
       "      <td>{0: 'People mostly look out for themselves', 1...</td>\n",
       "      <td>[{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...</td>\n",
       "      <td>%4.0g</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                              label  \\\n",
       "0       name                                   Title of dataset   \n",
       "1   essround                                          ESS round   \n",
       "2    edition                                            Edition   \n",
       "3   proddate                                    Production date   \n",
       "4       idno                 Respondent's identification number   \n",
       "5      cntry                                            Country   \n",
       "6    dweight                                      Design weight   \n",
       "7    pspwght  Post-stratification weight including design we...   \n",
       "8    pweight  Population size weight (must be combined with ...   \n",
       "9   anweight                                    Analysis weight   \n",
       "10      prob                               Sampling probability   \n",
       "11   stratum                                   Sampling stratum   \n",
       "12       psu                              Primary sampling unit   \n",
       "13    nwspol  News about politics and current affairs, watch...   \n",
       "14  netusoft                            Internet use, how often   \n",
       "15   netustm  Internet use, how much time on typical day, in...   \n",
       "16   ppltrst  Most people can be trusted or you can't be too...   \n",
       "17   pplfair  Most people try to take advantage of you, or t...   \n",
       "18    pplhlp  Most of the time people helpful or mostly look...   \n",
       "\n",
       "                                               values  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13  {'a': 'Refusal', 'b': \"Don't know\", 'c': 'No a...   \n",
       "14  {1: 'Never', 2: 'Only occasionally', 3: 'A few...   \n",
       "15  {'a': 'Not applicable', 'b': 'Refusal', 'c': \"...   \n",
       "16  {0: \"You can't be too careful\", 1: '1', 2: '2'...   \n",
       "17  {0: 'Most people try to take advantage of me',...   \n",
       "18  {0: 'People mostly look out for themselves', 1...   \n",
       "\n",
       "                                              missing format  measure  \n",
       "0                                                 NaN    %9s  unknown  \n",
       "1                                                 NaN  %3.0g  unknown  \n",
       "2                                                 NaN    %3s  unknown  \n",
       "3                                                 NaN   %10s  unknown  \n",
       "4                                                 NaN  %8.0g  unknown  \n",
       "5                                                 NaN    %2s  unknown  \n",
       "6                                                 NaN  %3.2g  unknown  \n",
       "7                                                 NaN  %3.2g  unknown  \n",
       "8                                                 NaN  %3.2g  unknown  \n",
       "9                                                 NaN  %4.2g  unknown  \n",
       "10                                                NaN  %3.2g  unknown  \n",
       "11                                                NaN  %6.0g  unknown  \n",
       "12                                                NaN  %7.0g  unknown  \n",
       "13  [{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...  %6.0g  unknown  \n",
       "14  [{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...  %3.0g  unknown  \n",
       "15  [{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...  %6.0g  unknown  \n",
       "16  [{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...  %4.0g  unknown  \n",
       "17  [{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...  %4.0g  unknown  \n",
       "18  [{'lo': 'a', 'hi': 'a'}, {'lo': 'b', 'hi': 'b'...  %4.0g  unknown  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_variable_view2(df_meta):\n",
    "    # Extract the attributes from df_meta\n",
    "    label = df_meta.column_names_to_labels\n",
    "    values = df_meta.variable_value_labels\n",
    "\n",
    "    # Convert user-defined missing values to the desired format\n",
    "    missing = {}\n",
    "    for key, vals in df_meta.missing_user_values.items():\n",
    "        missing[key] = [{\"lo\": val, \"hi\": val} for val in vals]\n",
    "\n",
    "    format = df_meta.original_variable_types\n",
    "    measure = df_meta.variable_measure\n",
    "\n",
    "    # Convert dictionaries into individual dataframes\n",
    "    df_label = pd.DataFrame(list(label.items()), columns=['name', 'label'])\n",
    "    df_format = pd.DataFrame(list(format.items()), columns=['name', 'format'])\n",
    "    df_measure = pd.DataFrame(list(measure.items()), columns=['name', 'measure'])\n",
    "\n",
    "    # For values and missing, handle them differently due to dictionaries/lists inside\n",
    "    df_values_list = [{'name': k, 'values': str(v)} for k, v in values.items()]  # Convert values to string\n",
    "    df_values = pd.DataFrame(df_values_list)\n",
    "\n",
    "    df_missing_list = [{'name': k, 'missing': str(v)} for k, v in missing.items()]  # Convert missing values to string\n",
    "    df_missing = pd.DataFrame(df_missing_list)\n",
    "\n",
    "    # Merge dataframes on the 'name' column\n",
    "    variable_view = df_label\n",
    "    if not df_values.empty:\n",
    "        variable_view = variable_view.merge(df_values, on='name', how='outer')\n",
    "    else:\n",
    "        variable_view['values'] = pd.NA\n",
    "    \n",
    "    if not df_missing.empty:\n",
    "        variable_view = variable_view.merge(df_missing, on='name', how='outer')\n",
    "    else:\n",
    "        variable_view['missing'] = pd.NA\n",
    "\n",
    "    variable_view = variable_view \\\n",
    "        .merge(df_format, on='name', how='outer') \\\n",
    "        .merge(df_measure, on='name', how='outer')\n",
    "\n",
    "    # Ensure 'values' and 'missing' columns are present\n",
    "    if 'values' not in variable_view.columns:\n",
    "        variable_view['values'] = pd.NA\n",
    "\n",
    "    if 'missing' not in variable_view.columns:\n",
    "        variable_view['missing'] = pd.NA\n",
    "\n",
    "    return variable_view\n",
    "\n",
    "create_variable_view2(df2_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e4e5dd9-5dc8-4a1f-bc5c-9c3efc4bd2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = df_meta.column_names_to_labels\n",
    "Values = df_meta.variable_value_labels\n",
    "Missing = df_meta.missing_ranges\n",
    "Format = df_meta.original_variable_types\n",
    "Measure = df_meta.variable_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "215309e3-3179-4bbe-876c-9bc5d1ead7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_InstanceVariable(df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for idx, variable in enumerate(df_meta.column_names):\n",
    "        elements = {\n",
    "            \"@id\": f\"#{variable}\",\n",
    "            \"@type\": \"InstanceVariable\",\n",
    "            \"name\": variable,\n",
    "            \"displayLabel\": df_meta.column_labels[idx],\n",
    "            \"hasIntendedDataType\": df_meta.original_variable_types[variable]\n",
    "        }\n",
    "\n",
    "        # Check if variable has substantive concepts\n",
    "        if variable in df_meta.variable_value_labels:\n",
    "            elements['takesSubstantiveConceptsFrom'] = f\"#substantiveConceptualDomain-{variable}\"\n",
    "\n",
    "        # Check if variable has sentinel concepts\n",
    "        if variable in df_meta.missing_ranges or (len(df_meta.missing_ranges) == 0 and variable in df_meta.missing_user_values):\n",
    "            elements['takesSentinelConceptsFrom'] = f\"#sentinelConceptualDomain-{variable}\"\n",
    "\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2bee657-7a42-4a15-ac1d-0fd4e4e2c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MeasureComponent\n",
    "def generate_MeasureComponent(df_meta):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.column_names[1:]):\n",
    "        elements = {\n",
    "            \"@id\": f\"#measureComponent-{variable}\",\n",
    "            \"@type\": \"MeasureComponent\",\n",
    "            \"isDefinedBy\": f\"#{variable}\"\n",
    "        }\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df52788f-e446-49ea-8f55-0c22db6bbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MeasureComponent2\n",
    "def generate_MeasureComponent2(df_meta, varlist=None):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.column_names):\n",
    "        if variable not in varlist:\n",
    "            elements = {\n",
    "                \"@id\": f\"#measureComponent-{variable}\",\n",
    "                \"@type\": \"MeasureComponent\",\n",
    "                \"isDefinedBy\": f\"#{variable}\"\n",
    "            }\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc33340e-7f92-45be-a0ce-69d144d11ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IdentifierComponent\n",
    "def generate_IdentifierComponent(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#identifierComponent-{df_meta.column_names[0]}\",\n",
    "        \"@type\": \"IdentifierComponent\",\n",
    "        \"isDefinedBy\": f\"#{df_meta.column_names[0]}\"\n",
    "    }\n",
    "    json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e806d81-5be7-4380-89a4-249fe91b3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IdentifierComponent2\n",
    "def generate_IdentifierComponent2(df_meta, varlist=None):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.column_names):\n",
    "        if variable in varlist:\n",
    "            elements = {\n",
    "                \"@id\": f\"#identifierComponent-{variable}\",\n",
    "                \"@type\": \"IdentifierComponent\",\n",
    "                \"isDefinedBy\": f\"#{variable}\"\n",
    "            }\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bfafd4a-7380-4d15-918c-91861bdefd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logicalRecord\n",
    "def generate_LogicalRecord(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#logicalRecord\",\n",
    "        \"@type\": \"LogicalRecord\",\n",
    "        \"organizes\": f\"#wideDataSet\"\n",
    "    }\n",
    "    has = []    \n",
    "    for x, variable in enumerate(df_meta.column_names):\n",
    "        has.append(f\"#{variable}\")\n",
    "    elements['has'] = has\n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c8b3b23-f5ce-4f79-b894-ae4687a6ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhysicalDataset\n",
    "def generate_PhysicalDataset(df_meta, spssfile):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#physicalDataset\",\n",
    "        \"@type\": \"PhysicalDataset\",\n",
    "        \"formats\": \"#dataStore\",\n",
    "        \"physicalFileName\": spssfile\n",
    "    }\n",
    "    has = [\"#physicalRecordSegment\"]\n",
    "    elements['has'] = has    \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d79e59ce-62fb-4a29-b3f0-15c892a843d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataStore\n",
    "def generate_DataStore(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#dataStore\",\n",
    "        \"@type\": \"DataStore\",\n",
    "        \"recordCount\": df_meta.number_rows\n",
    "    }\n",
    "    has = [\"#logicalRecord\"]\n",
    "    elements['has'] = has   \n",
    "    \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69090b36-4609-467d-b4c2-013f9b8802de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideDataSet\n",
    "def generate_WideDataSet(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#wideDataSet\",\n",
    "        \"@type\": \"WideDataSet\",\n",
    "        \"isStructuredBy\": \"#wideDataStructure\"\n",
    "    }\n",
    "    \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a38f3655-4365-4f09-9634-33ca36661137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideDataStructure\n",
    "def generate_WideDataStructure(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#wideDataStructure\",\n",
    "        \"@type\": \"WideDataStructure\",\n",
    "    }\n",
    "    has = [\"#primaryKey\", f\"#identifierComponent-{df_meta.column_names[0]}\"]\n",
    "    \n",
    "    for x, variable in enumerate(df_meta.column_names[1:]):\n",
    "        has.append(f\"#measureComponent-{variable}\")\n",
    "    elements['has'] = has\n",
    "        \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "875eb435-0ffb-405b-8889-0804167b778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideDataStructure2\n",
    "def generate_WideDataStructure2(df_meta, varlist=None):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#wideDataStructure\",\n",
    "        \"@type\": \"WideDataStructure\",\n",
    "    }\n",
    "    has = [\"#primaryKey\"]\n",
    "    \n",
    "    for x, variable in enumerate(df_meta.column_names):\n",
    "        if variable in varlist:\n",
    "            has.append(f\"#identifierComponent-{variable}\")\n",
    "        else:\n",
    "            has.append(f\"#measureComponent-{variable}\")\n",
    "    elements['has'] = has\n",
    "        \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "148f6ab8-742c-4528-a42a-040ad70bbe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrimaryKey\n",
    "def generate_PrimaryKey(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": \"#primaryKey\",\n",
    "        \"@type\": \"PrimaryKey\",\n",
    "        \"isComposedOf\": \"#primaryKeyComponent\"\n",
    "    }\n",
    "        \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8ee965d-e024-44b4-b59e-9b835321473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrimaryKeyComponent\n",
    "def generate_PrimaryKeyComponent(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": \"#primaryKeyComponent\",\n",
    "        \"@type\": \"PrimaryKeyComponent\",\n",
    "        \"correspondsTo\": f\"#identifierComponent-{df_meta.column_names[0]}\"\n",
    "    }\n",
    "        \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5993b67d-26ab-4fef-a6d0-5aa873207829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrimaryKeyComponent2\n",
    "def generate_PrimaryKeyComponent2(df_meta, varlist=None):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": \"#primaryKeyComponent\",\n",
    "        \"@type\": \"PrimaryKeyComponent\",\n",
    "    }\n",
    "    has = []    \n",
    "    for variable in varlist:\n",
    "        has.append(f\"#identifierComponent-{variable}\")\n",
    "    \n",
    "    elements['correspondsTo'] = has      \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "843cda54-ac03-42cd-bd2f-be655550aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhysicalRecordSegment\n",
    "def generate_PhysicalRecordSegment(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#physicalRecordSegment\",\n",
    "        \"@type\": \"PhysicalRecordSegment\",\n",
    "        \"mapsTo\": \"#logicalRecord\",\n",
    "    }\n",
    "    has = [\"#physicalSegmentLayout\"]\n",
    "    elements['has'] = has    \n",
    "    \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79bda048-f7a5-42b1-8d0c-1c3d01e905c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhysicalSegmentLayout\n",
    "def generate_PhysicalSegmentLayout(df_meta):\n",
    "    json_ld_data = []\n",
    "    elements = {\n",
    "        \"@id\": f\"#physicalSegmentLayout\",\n",
    "        \"@type\": \"PhysicalSegmentLayout\",\n",
    "        \"formats\": \"#logicalRecord\",\n",
    "        \"isDelimited\": \"false\",\n",
    "        \"delimiter\": \"\",\n",
    "    }\n",
    "    has = []    \n",
    "    for x, variable in enumerate(df_meta.column_names):\n",
    "        has.append(f\"#valueMapping-{variable}\")\n",
    "        has.append(f\"#valueMappingPosition-{variable}\")\n",
    "    elements['has'] = has    \n",
    "    json_ld_data.append(elements)\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "095b4f75-d942-4528-9292-7f81ec204781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueMapping\n",
    "def generate_ValueMapping(df, df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for idx, variable in enumerate(df_meta.column_names):\n",
    "        elements = {\n",
    "            \"@id\": f\"#valueMapping-{variable}\",\n",
    "            \"@type\": \"ValueMapping\",\n",
    "        }\n",
    "        datapoints = []\n",
    "        for i, x in enumerate(df[variable]):\n",
    "            datapoints.append(f\"#{variable}-dataPoint-{i}\")\n",
    "        elements['formats'] = datapoints\n",
    "\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fddcef52-5e6a-4650-a21c-31b0c93094b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueMappingPosition\n",
    "def generate_ValueMappingPosition(df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for idx, variable in enumerate(df_meta.column_names):\n",
    "        elements = {\n",
    "            \"@id\": f\"#valueMappingPosition-{variable}\",\n",
    "            \"@type\": \"ValueMappingPosition\",\n",
    "            \"value\": idx,\n",
    "            \"indexes\": f\"#valueMapping-{variable}\"\n",
    "        }\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "068797fd-9785-47a0-97ef-fc65d8b267da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataPoint\n",
    "def generate_DataPoint(df, df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for variable in (df_meta.column_names):\n",
    "        for idx, value in enumerate(df[variable]):\n",
    "            elements = {\n",
    "                \"@id\": f\"#{variable}-dataPoint-{idx}\",\n",
    "                \"@type\": \"DataPoint\",\n",
    "                \"isDescribedBy\": f\"#{variable}-instanceValue-{idx}\"\n",
    "            }\n",
    "\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d0327ea-d9db-442a-bbb4-34a708a37fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataPointPosition\n",
    "def generate_DataPointPosition(df, df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for variable in (df_meta.column_names):\n",
    "        for idx, value in enumerate(df[variable]):\n",
    "            elements = {\n",
    "                \"@id\": f\"#{variable}-dataPointPosition-{idx}\",\n",
    "                \"@type\": \"DataPointPosition\",\n",
    "                \"value\": idx,\n",
    "                \"indexes\": f\"#{variable}-dataPoint-{idx}\"\n",
    "            }\n",
    "\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "099d692b-f505-4070-97d3-b1346e1f31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubstantiveValueDomain\n",
    "def generate_SubstantiveValueDomain(df_meta):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.variable_value_labels):\n",
    "        elements = {\n",
    "            \"@id\": f\"#substantiveValueDomain-{variable}\",\n",
    "            \"@type\": \"SubstantiveValueDomain\",\n",
    "            \"takesValuesFrom\": f\"#codelist.{variable}\"\n",
    "        }\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "783c761f-ab0a-4092-9f54-c32fc9352887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstanceValue\n",
    "def generate_InstanceValue(df, df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Iterate through column names and associated index\n",
    "    for variable in (df_meta.column_names):\n",
    "        for idx, value in enumerate(df[variable]):\n",
    "            elements = {\n",
    "                \"@id\": f\"#{variable}-instanceValue-{idx}\",\n",
    "                \"@type\": \"InstanceValue\",\n",
    "                \"content\": value,\n",
    "                \"isStoredIn\": f\"#{variable}-dataPoint-{idx}\"\n",
    "            }\n",
    "\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "366f2403-ba48-440b-94c2-12cf5363e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codelist\n",
    "def generate_Codelist(df_meta):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.variable_value_labels.items()):\n",
    "        elements = {\n",
    "            \"@id\": f\"#codelist-{variable[x]}\",\n",
    "            \"@type\": \"Codelist\",\n",
    "        }\n",
    "        has = []\n",
    "        your_dict = variable[1]\n",
    "        # Loop through the dictionary and extract the keys\n",
    "        for key in your_dict.keys():\n",
    "            codes = {\n",
    "                \"@id\": f\"#code-{key}-{variable[x]}\"\n",
    "            }\n",
    "            has.append(codes)\n",
    "        elements['has'] = has    \n",
    "\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa8256bb-059c-4600-8e96-fa2fce198335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "def generate_Code(df_meta):\n",
    "    json_ld_data = []\n",
    "    for x, variable in enumerate(df_meta.variable_value_labels.items()):\n",
    "        your_dict = variable[1]\n",
    "        # Loop through the dictionary and extract the keys\n",
    "        for key, value in your_dict.items():\n",
    "            elements = {\n",
    "                \"@id\": f\"#code-{key}-{variable[x]}\",\n",
    "                \"@type\": \"Code\",\n",
    "            }\n",
    "            has = []\n",
    "            codes = {\n",
    "                \"@id\": f\"#{key}\"\n",
    "            }\n",
    "            has.append(codes)\n",
    "            elements['denotes'] = has\n",
    "\n",
    "            has = []\n",
    "            codes = {\n",
    "                \"@id\": f\"#{value}\"\n",
    "            }\n",
    "            has.append(codes)\n",
    "            elements['uses'] = has \n",
    "\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "011ce2d9-6448-4c22-8da0-059a6bb62ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubstantiveConceptualDomain\n",
    "def generate_SubstantiveConceptualDomain(df_meta):\n",
    "    json_ld_data = []\n",
    "    for variable in (df_meta.variable_value_labels):\n",
    "        elements = {\n",
    "            \"@id\": f\"#substantiveConceptualDomain-{variable}\",\n",
    "            \"@type\": \"SubstantiveConceptualDomain\",\n",
    "            \"takesConceptsFrom\": f\"#substantiveConceptScheme-{variable}\"\n",
    "        }\n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b2e07a42-50e8-4eeb-a1d3-2ef1d83b3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubstantiveConceptScheme\n",
    "def generate_SubstantiveConceptScheme(df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Determine the relevant variables based on the presence of missing values\n",
    "    relevant_variables = df_meta.missing_ranges if len(df_meta.missing_ranges) > 0 else df_meta.missing_user_values\n",
    "\n",
    "    for variable_name, values_dict in df_meta.variable_value_labels.items():\n",
    "        elements = {\n",
    "            \"@id\": f\"#substantiveConceptScheme-{variable_name}\",\n",
    "            \"@type\": \"skos:ConceptScheme\",\n",
    "        }\n",
    "\n",
    "        excluded_values = set()\n",
    "\n",
    "        # Check if variable_name is in relevant_variables\n",
    "        if variable_name in relevant_variables:\n",
    "            \n",
    "            # If the relevant variable data is based on ranges and contains dictionaries\n",
    "            if isinstance(relevant_variables[variable_name], list) and all(isinstance(item, dict) for item in relevant_variables[variable_name]):\n",
    "                for dict_range in relevant_variables[variable_name]:\n",
    "                    lo_is_numeric = isinstance(dict_range['lo'], (int, float)) or (\n",
    "                        isinstance(dict_range['lo'], str) and dict_range['lo'].isnumeric()\n",
    "                    )\n",
    "                    hi_is_numeric = isinstance(dict_range['hi'], (int, float)) or (\n",
    "                        isinstance(dict_range['hi'], str) and dict_range['hi'].isnumeric()\n",
    "                    )\n",
    "\n",
    "                    if lo_is_numeric and hi_is_numeric:\n",
    "                        excluded_values.update(\n",
    "                            range(int(float(dict_range['lo'])), int(float(dict_range['hi'])) + 1)\n",
    "                        )\n",
    "                    elif isinstance(dict_range['lo'], str):\n",
    "                        excluded_values.add(dict_range['lo'])\n",
    "                    else:\n",
    "                        print(f\"Warning: Unsupported 'lo' value: {dict_range['lo']}\")\n",
    "\n",
    "            # If the relevant variable data contains strings (user-defined missing values)\n",
    "            elif isinstance(relevant_variables[variable_name], list):\n",
    "                excluded_values.update(set(map(str, relevant_variables[variable_name])))\n",
    "\n",
    "        # Use list comprehension to generate the hasTopConcept list\n",
    "        has_top_concept = [\n",
    "            f\"#{variable_name}-concept-{value}\"\n",
    "            for value in values_dict.keys()\n",
    "            if str(value) not in excluded_values\n",
    "        ]\n",
    "\n",
    "        # Only add to json_ld_data if has_top_concept list is not empty\n",
    "        if has_top_concept:\n",
    "            elements['skos:hasTopConcept'] = has_top_concept\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad2af43d-dd38-4322-8603-bb5577f980c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueAndConceptDescription\n",
    "def generate_ValueAndConceptDescription(df_meta):\n",
    "    # Determine the relevant variables based on the presence of missing values\n",
    "    relevant_variables = df_meta.missing_ranges if len(df_meta.missing_ranges) > 0 else df_meta.missing_user_values\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            \"@id\": f\"#valueAndConceptDescription-{variable}\",\n",
    "            \"@type\": \"ValueAndConceptDescription\",\n",
    "            \"isDescribedBy\": str(value),\n",
    "        }\n",
    "        for variable, value in relevant_variables.items()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f24d6aeb-e246-4381-b8b4-458ee2f2b48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'@id': '#sentinelConceptualDomain-MARST',\n",
       "  '@type': 'SentinelConceptualDomain',\n",
       "  'isDescribedBy': '#valueAndConceptDescription-MARST',\n",
       "  'takesConceptsFrom': '#sentinelConceptScheme-MARST'},\n",
       " {'@id': '#sentinelConceptualDomain-PWT',\n",
       "  '@type': 'SentinelConceptualDomain',\n",
       "  'isDescribedBy': '#valueAndConceptDescription-PWT'},\n",
       " {'@id': '#sentinelConceptualDomain-testvar',\n",
       "  '@type': 'SentinelConceptualDomain',\n",
       "  'isDescribedBy': '#valueAndConceptDescription-testvar',\n",
       "  'takesConceptsFrom': '#sentinelConceptScheme-testvar'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SentinelConceptualDomain\n",
    "def generate_SentinelConceptualDomain(df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Determine the relevant variables based on the presence of missing values\n",
    "    relevant_variables = df_meta.missing_ranges if len(df_meta.missing_ranges) > 0 else df_meta.missing_user_values\n",
    "\n",
    "    for variable in relevant_variables:\n",
    "        elements = {\n",
    "            \"@id\": f\"#sentinelConceptualDomain-{variable}\",\n",
    "            \"@type\": \"SentinelConceptualDomain\",\n",
    "            \"isDescribedBy\": f\"#valueAndConceptDescription-{variable}\",\n",
    "        }\n",
    "        if variable in df_meta.variable_value_labels.keys():\n",
    "            elements[\"takesConceptsFrom\"] = f\"#sentinelConceptScheme-{variable}\"\n",
    "            \n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data\n",
    "generate_SentinelConceptualDomain(df_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e5b042c-1b16-48d8-ad16-6bc6c4ef33fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MARST': [{'lo': 7.0, 'hi': 8.0}, {'lo': 9.0, 'hi': 9.0}],\n",
       " 'PWT': [{'lo': -8.0, 'hi': -8.0}, {'lo': -9.0, 'hi': -9.0}],\n",
       " 'testvar': [{'lo': '7', 'hi': '7'},\n",
       "  {'lo': '8', 'hi': '8'},\n",
       "  {'lo': '9', 'hi': '9'}]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.missing_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc984416-e011-4e40-b337-18eaa85f4d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'netustm': ['a', 'b', 'c', 'd'],\n",
       " 'pplfair': ['a', 'b', 'c'],\n",
       " 'nwspol': ['a', 'b', 'c'],\n",
       " 'pplhlp': ['a', 'b', 'c'],\n",
       " 'ppltrst': ['a', 'b', 'c'],\n",
       " 'netusoft': ['a', 'b', 'c']}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_meta.missing_user_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8bf3ca73-bc0a-4279-9b55-0e0a1e32ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_SentinelConceptScheme\n",
    "def generate_SentinelConceptScheme(df_meta):\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Determine the relevant variables based on the presence of missing values\n",
    "    relevant_variables = df_meta.missing_ranges if len(df_meta.missing_ranges) > 0 else df_meta.missing_user_values\n",
    "\n",
    "    def is_value_in_range(value, ranges):\n",
    "        \"\"\"Check if a value is in any of the given ranges.\"\"\"\n",
    "        for range_dict in ranges:\n",
    "            if range_dict['lo'] <= value <= range_dict['hi']:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    for variable_name, values_dict in df_meta.variable_value_labels.items():\n",
    "        elements = {\n",
    "            \"@id\": f\"#sentinelConceptScheme-{variable_name}\",\n",
    "            \"@type\": \"skos:ConceptScheme\",\n",
    "        }\n",
    "\n",
    "        has_top_concept = []\n",
    "        \n",
    "        if variable_name in relevant_variables:\n",
    "            if variable_name in df_meta.missing_ranges:\n",
    "                # Use list comprehension to generate the hasTopConcept list\n",
    "                has_top_concept = [\n",
    "                    f\"#{variable_name}-concept-{value}\"\n",
    "                    for value in values_dict.keys()\n",
    "                    if is_value_in_range(value, df_meta.missing_ranges[variable_name])\n",
    "                ]\n",
    "            else:\n",
    "                excluded_values = set(df_meta.missing_user_values[variable_name])\n",
    "                has_top_concept = [\n",
    "                    f\"#{variable_name}-concept-{value}\"\n",
    "                    for value in values_dict.keys()\n",
    "                    if value in excluded_values\n",
    "                ]\n",
    "        \n",
    "        # Add the hasTopConcept list to elements\n",
    "        elements['skos:hasTopConcept'] = has_top_concept\n",
    "        \n",
    "        json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a9c6f0e-f5b7-4fe7-81c2-d1a35d6d5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept\n",
    "def generate_Concept(df_meta):\n",
    "    def is_value_in_excluded_ranges(value, excluded_ranges):\n",
    "        if isinstance(value, (int, float)):\n",
    "            return value in excluded_ranges\n",
    "        elif isinstance(value, str):\n",
    "            return value in excluded_ranges\n",
    "        return False\n",
    "\n",
    "    json_ld_data = []\n",
    "\n",
    "    # Convert user-defined missing values to the desired format\n",
    "    if df_meta.missing_user_values:\n",
    "        missing = {}\n",
    "        for key, vals in df_meta.missing_user_values.items():\n",
    "            missing[key] = [{\"lo\": val, \"hi\": val} for val in vals]\n",
    "    else:\n",
    "        missing = df_meta.missing_ranges\n",
    "\n",
    "    for variable_name, values_dict in df_meta.variable_value_labels.items():\n",
    "        # Check if variable_name is in missing and, if so, generate the excluded_ranges\n",
    "        excluded_ranges = set()\n",
    "        if variable_name in missing:\n",
    "            for dict_range in missing[variable_name]:\n",
    "                lo_is_numeric = isinstance(dict_range['lo'], (int, float)) or (\n",
    "                    isinstance(dict_range['lo'], str) and dict_range['lo'].isnumeric()\n",
    "                )\n",
    "                hi_is_numeric = isinstance(dict_range['hi'], (int, float)) or (\n",
    "                    isinstance(dict_range['hi'], str) and dict_range['hi'].isnumeric()\n",
    "                )\n",
    "\n",
    "                if lo_is_numeric and hi_is_numeric:\n",
    "                    # Case: 'lo' and 'hi' can be converted to int\n",
    "                    excluded_ranges.update(\n",
    "                        range(int(float(dict_range['lo'])), int(float(dict_range['hi'])) + 1)\n",
    "                    )\n",
    "                elif isinstance(dict_range['lo'], str) and dict_range['lo'] == dict_range['hi']:\n",
    "                    # Case: 'lo' and 'hi' are the same non-numeric string\n",
    "                    excluded_ranges.add(dict_range['lo'])\n",
    "                else:\n",
    "                    print(f\"Warning: Unsupported 'lo' value: {dict_range['lo']}\")\n",
    "\n",
    "        # Iterate through values_dict and create elements, taking into account excluded_keys\n",
    "        for key, value in values_dict.items():\n",
    "            elements = {\n",
    "                \"@id\": f\"#{variable_name}-concept-{key}\",\n",
    "                \"@type\": \"skos:Concept\",\n",
    "                \"notation\": key,\n",
    "                \"prefLabel\": f\"{value}\",\n",
    "            }\n",
    "\n",
    "            # Add the inScheme key to elements based on whether the key is in excluded_ranges\n",
    "            if is_value_in_excluded_ranges(key, excluded_ranges):\n",
    "                elements['inScheme'] = f\"#sentinelConceptScheme-{variable_name}\"\n",
    "            else:\n",
    "                elements['inScheme'] = f\"#substantiveConceptScheme-{variable_name}\"\n",
    "\n",
    "            # Append elements to json_ld_data inside the loop\n",
    "            json_ld_data.append(elements)\n",
    "\n",
    "    return json_ld_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d0eb8-8f69-433d-8ad2-2f2299d074b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate JSON-LD\n",
    "InstanceVariable = generate_InstanceVariable(df_meta)\n",
    "#SubstantiveValueDomain = generate_SubstantiveValueDomain(df_meta)\n",
    "SubstantiveConceptualDomain = generate_SubstantiveConceptualDomain(df_meta)\n",
    "SentinelConceptualDomain = generate_SentinelConceptualDomain(df_meta)\n",
    "ValueAndConceptDescription = generate_ValueAndConceptDescription(df_meta)\n",
    "SubstantiveConceptScheme = generate_SubstantiveConceptScheme(df_meta)\n",
    "SentinelConceptScheme = generate_SentinelConceptScheme(df_meta)\n",
    "Concept = generate_Concept(df_meta)\n",
    "#Codelist = generate_Codelist(df_meta)\n",
    "#Code = generate_Code(df_meta)\n",
    "LogicalRecord = generate_LogicalRecord(df_meta)\n",
    "PhysicalDataset = generate_PhysicalDataset(df_meta, spssfile)\n",
    "PhysicalRecordSegment = generate_PhysicalRecordSegment(df_meta)\n",
    "PhysicalSegmentLayout = generate_PhysicalSegmentLayout(df_meta)\n",
    "ValueMapping = generate_ValueMapping(df, df_meta)\n",
    "ValueMappingPosition = generate_ValueMappingPosition(df_meta)\n",
    "InstanceValue = generate_InstanceValue(df, df_meta)\n",
    "DataPoint = generate_DataPoint(df, df_meta)\n",
    "DataPointPosition = generate_DataPointPosition(df, df_meta)\n",
    "DataStore = generate_DataStore(df_meta)\n",
    "WideDataSet = generate_WideDataSet(df_meta)\n",
    "WideDataStructure = generate_WideDataStructure(df_meta)\n",
    "PrimaryKey = generate_PrimaryKey(df_meta)\n",
    "PrimaryKeyComponent = generate_PrimaryKeyComponent(df_meta)\n",
    "MeasureComponent = generate_MeasureComponent(df_meta)\n",
    "IdentifierComponent = generate_IdentifierComponent(df_meta)\n",
    "\n",
    "\n",
    "json_ld_graph = DataStore + PhysicalDataset + PhysicalRecordSegment + PhysicalSegmentLayout + ValueMapping + \\\n",
    "ValueMappingPosition + DataPoint + DataPointPosition + InstanceValue + LogicalRecord + WideDataSet + \\\n",
    "WideDataStructure + IdentifierComponent + MeasureComponent + PrimaryKey + PrimaryKeyComponent + InstanceVariable + \\\n",
    "SubstantiveConceptualDomain + SubstantiveConceptScheme + SentinelConceptualDomain + ValueAndConceptDescription + \\\n",
    "SentinelConceptScheme + Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1118950d-a1f6-4bb7-ac30-0fc2269359d4",
   "metadata": {},
   "source": [
    "## Create Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23010e43-e449-41b9-8d68-c751cff7e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the specified \"@context\" and \"@graph\" keys\n",
    "json_ld_dict = {\n",
    "    \"@context\": [\n",
    "        \"https://ddi-alliance.bitbucket.io/DDI-CDI/DDI-CDI_v1.0-rc1/encoding/json-ld/ddi-cdi.jsonld\",\n",
    "        {\n",
    "            \"skos\": \"http://www.w3.org/2004/02/skos/core#\"\n",
    "        }\n",
    "    ],\n",
    "    \"@graph\": json_ld_graph\n",
    "}\n",
    "\n",
    "def default_encode(obj):\n",
    "    if isinstance(obj, np.int64):\n",
    "        return int(obj)\n",
    "    elif pd.isna(obj):  # Checks for pd.NA\n",
    "        return None\n",
    "    elif isinstance(obj, pd.Timestamp):  # Checks for Timestamp\n",
    "        return obj.isoformat()\n",
    "    raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert the Python dictionary to a JSON string with pretty formatting\n",
    "\n",
    "json_ld_string = json.dumps(json_ld_dict, indent=4, default=default_encode)\n",
    "# New code to write the JSON-LD string to a file\n",
    "with open('output.jsonld', 'w') as file:\n",
    "    file.write(json_ld_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29306f-faec-430f-880b-dd69375054ba",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
